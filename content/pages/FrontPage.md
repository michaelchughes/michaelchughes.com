Title: Mike Hughes - Machine Learning Research
Date: 2018-07-01
save_as: index.html

Welcome! My research spans statistical machine learning and its applications in healthcare and the sciences.

I am an Assistant Professor in the Dept. of Computer Science at Tufts University and a primary faculty member for the 
[Tufts Machine Learning research group](https://www.cs.tufts.edu/research/ml/).
Previously, I was a postdoctoral fellow in computer science at Harvard SEAS, advised by 
<a href="https://finale.seas.harvard.edu/">Prof. Finale Doshi-Velez</a>. 
I completed my Ph.D. in Computer Science at Brown University, advised by <a href="https://www.ics.uci.edu/~sudderth/">Prof. Erik Sudderth</a> (now at UC-Irvine).

### Research Highlights

First, my lab pursues methodological advances in statistical machine learning:

* probabilistic models for time-series (see papers from [arXiv 2024](https://arxiv.org/abs/2401.14973), [NeurIPS 2021](https://papers.nips.cc/paper/2021/file/ebb71045453f38676c40deb9864f811d-Paper.pdf) or [AOAS 2014](https://www.michaelchughes.com/papers/FoxHughesSudderthJordan_AOAS_2014.pdf))
* probabilistic approaches to transfer learning ([TMLR 2024](https://openreview.net/forum?id=BbvSU02jLg)) or supervised contrastive learning ([arXiv 2024](https://arxiv.org/abs/2309.14277))
* semi-supervised learning with discriminative neural networks ([ICML 2024](https://proceedings.mlr.press/v235/huang24af.html), [CVPR 2024](https://arxiv.org/abs/2307.08919), [AISTATS 2023](https://www.michaelchughes.com/papers/HuangSidhomEtAl_AISTATS_2023.pdf))
* semi-supervised learning with generative models ([AISTATS 2018]({static}/papers/HughesEtAl_AISTATS_2018.pdf), [Time Series Workshop 2021]({static}/papers/HopeEtAl_TimeSeriesWorkshopAtICML_2021.pdf), and [AABI 2022](https://openreview.net/pdf?id=pmLjKZsCvPt))
* optimizing early warning classifiers to control false alarms ([AISTATS 2022]({static}/papers/RathHughes_AISTATS_2022.pdf))

Second, I pursue high-impact clinical and scientific applications of these techniques:

* automating preliminary diagnosis of heart disease using echocardiograms ([MLHC '21]({static}/papers/HuangEtAl_MLHC_2021.pdf), [J Am Soc Echo '23](https://www.onlinejase.com/article/S0894-7317\(23\)00014-7/pdf))
* spatiotemporal forecasting of the opioid overdose epidemic ([Am. Journal of Epi. '24](https://doi.org/10.1093/aje/kwae343))
* predicting patient risks in the Intensive Care Unit (ICU) ([CHIL '20 paper]({static}/papers/WangMcDermottEtAl_CHIL_2020.pdf) and [MIMIC-Extract code](https://github.com/MLforHealth/MIMIC_Extract))
* recommending stable antidepressants personalized to patients ([JAMA Network Open 2020]({static}/papers/HughesPradierRossEtAl_JAMANetworkOpen_2020.pdf))
* forecasting demand for hospital resources during the COVID-19 pandemic ([MLHC '21]({static}/papers/VisaniEtAl_MLHC_2021.pdf))

For more, see my [Research page]({static}/research.html)


### News

<ul class="list-group">
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Sep 2024] Paper on spatiotemporal forecasting of opioid overdose epidemic
        </h4>
        <ul>
            <li><a href="https://doi.org/10.1093/aje/kwae343">
                [paper at Am J. Epi.]</a>, Led by PhD student Kyle Heuton (Tufts CS)
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Jul 2024] Grateful to receive an NSF CAREER award to fund our lab's work
        </h4>
        <ul>
            <li><a href="https://engineering.tufts.edu/news-events/news/hughes-receives-nsf-career-award">
                Article on Tufts SoE News website</a>
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [May 2024] Paper on a new semi-supervised learning method at ICML 2024 in Vienna
        </h4>
        <ul>
            <li><a href="https://proceedings.mlr.press/v235/huang24af.html">
                [PDF]</a>, Led by PhD student Zhe Huang (Tufts CS)
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Mar 2024] Paper for benchmarking semi- and self-supervised learning at CVPR 2024 in Seattle
        </h4>
        <ul>
            <li><a href="https://arxiv.org/abs/2307.08919">
                [arXiv]
                </a>,  Led by PhD students Zhe Huang (Tufts CS) and Ruijie Jiang (Tufts ECE)
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Feb 2024] Grateful to be part of a NIH-funded R01 project on neuroimaging
        </h4>
        <ul>
            <li><a href="https://www.tuftsmedicine.org/about-us/news/3-million-dollar-grant-cerebrovascular-research-expanding-research-across-tufts-medicine">
                Tufts Med news article</a>
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Dec 2023] Work on extrapolating classifier performance at ML4H 2023
        </h4>
        <ul>
            <li><a href="https://proceedings.mlr.press/v225/harvey23a.html">
                [Link to Paper PDF]
                </a>, Led by PhD student Ethan Harvey
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Oct 2023] Grateful for support from Alzheimer's Drug Discovery Foundation 
        </h4>
        <ul>
            <li><a href="https://www.alzdiscovery.org/research-and-grants/portfolio-details/21977527">
                [Award Page]</a> This is a collaboration between Tufts U./ Tufts Med. / Kaiser Permente.
            </li>
            <li> Hughes Lab will lead development of deep learning to detect early signs of stroke/dementia
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Aug 2023] Work on multiple instance learning at MLHC 2023
        </h4>
        <ul>
            <li><a href="https://arxiv.org/abs/2306.00003">
                [arXiv]
                </a>, Led by PhD student Zhe Huang
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Apr 2023] Fix-A-Step paper selected for oral presentation at AISTATS '23 (top 2% of 1500+ reviewed papers)
        </h4>
        <ul>
            <li>Paper: <a href="https://arxiv.org/abs/2208.11870">Fix-A-Step: Effective Semi-supervised Learning from Uncurated Data</a>
            </li>
            <li> Led by PhD student Zhe Huang, Key contributions from undergraduate Mary-Joy Sidhom
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Jan 2023] Clinical journal publication on automated diagnosis of heart valve disease
        </h4>
        <ul>
            <li> We present a deep learning method for predicting the severity of a common heart valve disease called aortic stenosis given images from a routine echocardiogram
            </li>
            <li> We have careful validation both in a new temporal cohort at Tufts and another external cohort of 8500+ images
            </li>
            <li> We've also released an open-access dataset: <a href="https://tmed.cs.tufts.edu">TMED-2</a>
            </li>
            <li> Among many great co-authors, I especially credit
                <ul>
                    <li> Zhe Huang, PhD student : lead the computational aspects</li>
                    <li> Ben Wessler, MD: cardiologist leading the project
                    </li>
                </ul>
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Nov 2022] Three papers at upcoming workshops at NeurIPS '22
        </h4>
        <ul>
            <li> Kyle Heuton presents a <a href="{static}/papers/HeutonEtAl_GPSpatiotemporalWorkshop_2022.pdf">new Gaussian process model for spatiotemporal forecasting of opioid-related overdose deaths</a>
            </li>
            <li> Preetish Rath presents a <a href="{static}/papers/RathEtAl_TS4HWorkshop_2022.pdf">new probabilistic approach for predicting patient outcomes from semi-supervised medical time series with missing features</a>
            </li>
            <li> Zhe Huang presents a <a href="{static}/papers/HuangSidhomEtAl_MedNeurIPS_2022.pdf">new way to train semi-supervised deep classifiers for medical images</a> even when unlabeled data differs from labeled data
            </li>
                <ul>
                    <li> Our method, Fix-A-Step, is described in a <a href="https://arxiv.org/abs/2208.11870">longer preprint on arXiv</a></li>
                    <li> Includes new Heart2Heart benchmark for evaluating models trained in US on patients from France/UK</li>
                </ul>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [July 2022] Paper at ICML 2022
        </h4>
        <ul>
            <li> <a href="{static}/papers/WojnowiczEtAl_ICML_2022.pdf"> Easy Variational Inference for Categorical Models via an Independent Binary Approximation
            </li>
            <ul>
                <li> Led by <a href="https://scholar.google.com/citations?user=5O4vP3EAAAAJ&hl=en">Mike Wojnowicz</a>, a <a href="https://disc.tufts.edu/">data scientist at Tufts DISC</a>
                </li>
                <li><p>
                    Linear models with categorical outcomes can be tough to fit in Bayesian fashion, especially when number of categories are large. We show how classic Bayesian auxiliary variable methods (probit, logit) for one-hot binary models can be <i>justified</i> as principled surrogates of a new class of truly one-of-K categorical models via a likelihood bound. While it has been common for decades to train many simple binary classifiers via a "one vs rest" (aka one vs all) paradigm, the statistical justification for this choice has often been questioned. This work offers a firm foundation for why this independent binary approximation may be successful.
                </p>
                </li>
            </ul>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Feb 2022] Paper at AISTATS 2022
        </h4>
        <ul>
            <li> <a href="{static}/papers/RathHughes_AISTATS_2022.pdf">
            Optimizing Early Warning Classifiers to Control False Alarms via a Minimum Precision Constraint</a>
            </li>
            <ul>
                <li> Led by PhD student Preetish Rath
                </li>
                <li> See this <a href="https://twitter.com/mike_c_hughes/status/1509177256836489222">Twitter thread overview</a>
                </li>
            </ul>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Dec 2021] Two papers on time series appearing at NeurIPS 2021
        </h4>
        <ul>
            <li> <a href="https://papers.nips.cc/paper/2021/file/ebb71045453f38676c40deb9864f811d-Paper.pdf">
                Dynamical Wasserstein Barycenters for Time-Series Modeling [PDF]
            </a></li>
            <ul>
                <li> Led by Tufts EE PhD student Kevin Cheng (co-advised)
                </li>
            </ul>
            <li> In the Datasets Track: <a href="https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/bd686fd640be98efaae0091fa301e613-Paper-round2.pdf">The Tufts fNIRS Mental Workload Dataset & Benchmark for Brain-Computer Interfaces that Generalize [PDF] </a>
            </li>
            <ul>
                <li> Led by Tufts CS PhD student Zhe Huang
                </li>
                <li> Featured in <a href="https://now.tufts.edu/articles/getting-better-performance-brains-and-computers">an article on Tufts Now (Feb '22)</a>
                </li>
            </ul>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Aug 2021] Two papers from HughesLab appearing at MLHC 2021
        </h4>
        <ul>
            <li> <a href="{static}/papers/VisaniEtAl_MLHC_2021.pdf">Approximate Bayesian Computation for an Explicit-Duration Hidden Markov Model of COVID-19 Hospital Trajectories [PDF] </a>
            </li>
            <ul>
                <li> This is a new model for forecasting daily demand for hospital beds from COVID-19 patients.
                </li>
                <li> Led by first author Gian Marco Visani (Tufts CS undergrad '21)
                </li>
                <li> With key help two other student co-authors: Ally Lee and Cuong Nguyen
                </li>
                <li> With two collaborators from Tufts Medical Center: David Kent, MD and John Wong, MD (both clinician-researchers) 
                </li>
                <li> With one collaborator from the Center for the Evaluation of Value and Risk in Health at TMC: <a href="https://www.tuftsmedicalcenter.org/physiciandirectory/joshua-cohen"> Josh Cohen </a>, a researcher in applied math/decision sciences/health economics
                </li>
            </ul>
        </ul>
        <ul>
            <li> <a href="{static}/papers/HuangEtAl_MLHC_2021.pdf"> A New Semi-supervised Learning Benchmark for Classifying View and Diagnosing Aortic Stenosis from Echocardiograms [PDF] </a>
            </li>
            <ul>
                <li> This is a new dataset release in pursuit of two goals: (1) improved early detection of heart disease (aortic stenosis) and (2) improved methods that can learn from both limited labeled datasets and abundant uncurated unlabeled data via semi-supervised learning
                <li> 
                    Data and code available at <a href="https://TMED.cs.tufts.edu">https://TMED.cs.tufts.edu</a>
                </li>
                <li> Led by first author Zhe Huang (Tufts CS Ph.D. student)
                </li>
                <li> With co-PI and key collaborator from Tufts Medical Center: <a href="https://www.tuftsmedicalcenter.org/physiciandirectory/benjamin-wessler">Dr. Ben Wessler, MD</a>
                </li>
            </ul>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [July 2021] New preprint on easy conjugate Bayesian methods for categorical data
        </h4>
        <ul>
            <li> Will be at the <a href="https://sites.google.com/view/tpm2021/">Tractable Probabilistic Modeling (TPM) workshop </a> (co-located with UAI) to present our <a href="{static}/papers/WojnowiczEtAl_TPM_2021.pdf">paper on Easy Variational Inference for Categorical Observations via a New View of Diagonal Orthant Probit Models</a>, 
            led by <a href="https://scholar.google.com/citations?user=5O4vP3EAAAAJ&hl=en">Mike Wojnowicz (Tufts DISC)</a>
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [July 2021] Three papers accepted to workshops at ICML
        </h4>
        <ul>
            <li> Will be at the <a href="https://sites.google.com/view/imlh2021/">Interpretable Machine Learning for Healthcare (IMLH)</a> workshop to present our <a href="{static}/papers/RathHughes_IMLH_2021.pdf">paper on Optimizing Clinical Early Warning Systems to Meet False Alarm Constraints</a>, led by Ph.D. student Preetish Rath
            </li>
            <li> Will be at the <a href="https://sites.google.com/view/udlworkshop2021/home">Uncertainty and Robustness in Deep Learning (UDL) workshop</a> to present our <a href="{static}/papers/FeeneyHughes_UDL_2021.pdf">paper on Evaluating the Use of Reconstruction Error for Novelty Localization</a>, led by Ph.D. student Patrick Feeney
            </li>
            <li> Will be at the <a href="http://roseyu.com/time-series-workshop/#introduction">Time Series Workshop (TSW) </a> to present our <a href="{static}/papers/HopeEtAl_TimeSeriesWorkshopAtICML_2021.pdf">paper on Prediction-Constrained Hidden Markov Models for Semi-Supervised Classification</a>, led by UC-Irvine Ph.D. student Gabe Hope. <b>UPDATE: Gabe's poster received the Best Poster award at the TWS workshop!</b>
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [July 2021] Work on Graph Matching accepted at ICML 2021
        </h4>
        <ul>
            <li> Check out our <a href="{static}/papers/LiuEtAl_ICML_2021.pdf">paper on Stochastic Iterative Graph Matching (SIGMA)</a> a probabilistic approach to finding a correspondence between the nodes of two similar graphs, with several collaborators from Tufts CS: Ph.D. student Linfeng Liu and faculty colleagues Soha Hassoun and Liping Liu
            </li>
            <li> Cool evaluations on applications from systems biology and computer vision
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Apr 2021] New work on probabilistic models for COVID-19 forecasting, with collaborators from Tufts Medical Center
        </h4>
        <ul>
            <li>
                Preprint on a new <a href="{static}/papers/VisaniEtAl_arXiv_2021.pdf"> ACED-HMM model for COVID-19 hospitalized patient trajectories </a>, led by first author Gian Marco Visani (Tufts CS undergrad '21)
            </li>
            <li> Workshop paper on <a href="{static}/papers/LeeEtAl_ICLRWorkshopMLPreventingCombatingPandemics_2021.pdf"> COVID-19 patient count forecasting at a single hospital</a>, led by first author Alexandra Lee (Tufts CS undergrad '20)
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Dec 2020] Invited Talk at I Can't Believe It's Not Better Workshop at NeurIPS 2020
        </h4>
        <ul>
            <li>
                I'll be an invited speaker at the <a href="https://i-cant-believe-its-not-better.github.io/schedule/">I Can't Believe It's Not Better! Workshop</a> at NeurIPS 2020
            </li>
            <li>
                I'll talk about our recent work on Prediction Constrained training, covering in progress work <a href="https://arxiv.org/pdf/2012.06718.pdf">(Hope et al. arXiv 2020)</a> as well as recent publications at AISTATS 2018 and AISTATS 2020.
            </li>
            <li> <a href="https://slideslive.com/38938369/i-cant-believe-supervision-for-latent-variable-models-is-not-better-the-case-for-prediction-constrained-training"> Video recording </a>
            <li>
                Slides: <a href="{static}/talks/20201211_Talk_TheCaseForPredictionConstrainedTraining_CantBelieveNotBetterWorkshop.pdf"> The Case For Prediction Constrained Training [PDF] </a>
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [May 2020] Paper applying our latest ML methods to psychiatry accepted to JAMA Network Open
        </h4>
        <ul>
            <li>
                <a href="{static}/papers/HughesPradierRossEtAl_JAMANetworkOpen_2020.pdf">
                Assessment of a Prediction Model for Antidepressant Treatment Stability Using Supervised Topic Models
                </a>
            </li>
            <li>
                Read this to understand how to use our latest prediction-constrained topic models to recommending personalized antidepressants.
            </li>
            <li>
                <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2766073"> Full paper and supplement available at jamanetwork.com </a>
            </li>
            <li>
                Special thanks to awesome clinical collaborators Roy Perlis MD and Tom McCoy MD.
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Jan 2020] Paper accepted at <a href="https://www.aistats.org/">AISTATS 2020</a>
        </h4>
        <ul>
            <li>
                <a href="{static}/papers/FutomaHughesDoshiVelez_AISTATS_2020.pdf">
                POPCORN: Partially Observed Prediction-Constrained Reinforcement Learning
                </a> by Joseph Futoma, Michael C. Hughes, and Finale Doshi-Velez
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Dec 2019] Two papers accepted at <a href="http://www.approximateinference.org/">AABI 2019</a>
        </h4>
        <ul>
            <li>
                <a href="{static}/papers/ZhangHughes_AABI_2019.pdf">
                Amortized Variational Inference for Rapid Model Comparison
                </a>, with first author <a href="https://www.linkedin.com/in/lilyhzhang">Lily Zhang</a
            </li>
            <li>
                <a href="{static}/papers/PradierHughesDoshiVelez_AABI_2019.pdf">
                Challenges in Computing and Optimizing Upper Bounds of Marginal Likelihood based on Chi-Square Divergences 
                </a>, with Melanie F. Pradier and Finale Doshi-Velez
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Nov 2019] Paper Accepted at <a href="">AAAI 2020</a>
        </h4>
        <ul>
            <li>
                <a href="{static}/papers/WuParbhooHughesEtAl_AAAI_2020.pdf">
                Regional Tree Regularization for Interpretability in Deep Neural Networks
                </a>
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Aug 2019] Paper Accepted at <a href="">MLHC 2019</a>
        </h4>
        <ul>
            <li>
                <a href="{static}/papers/NestorEtAl_MLHC_2019.pdf">
                    Feature Robustness in Non-stationary Health Records:
                    Caveats to Deployable Model Performance in Common Clinical Machine Learning Tasks
                </a>
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [June 2019] Invited Talk at <a href="">BNP 12</a>
        </h4>
        <ul>
            <li>"Scalable and Reliable Variational Inference for Dirichlet Process Clustering with Sparse Assignments"
            </li>
            <li>
            Venue: <a href="https://www.stats.ox.ac.uk/bnp12/programme.html">12th International Conference on Bayesian Nonparametrics</a>
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Dec 2018] Two short papers accepted to workshops at NeurIPS 2018
        </h4>
        <ul>
            <li>
                <a href="{static}/papers/FutomaHughesDoshi_RLPOWorkshop2018.pdf">
                    Prediction-Constrained POMDPs
                </a> at RLPO @ NeurIPS2018
            </li>
            <li>
                <a href="{static}/papers/NestorEtAl_ML4HWorkshop2018.pdf">
                    Rethinking clinical prediction: Why machine learning must consider year of care and feature aggregation
                </a> at ML4Health @ NeurIPS 2018
            </li>
        </ul>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Aug 2018] I'm organizing 2 Workshops at NeurIPS 2018:
        </h4>
        <ul>
            <li>
            <a href="https://sites.google.com/view/nipsbnp2018">
            All of Bayesian Nonparametrics (BNP @ NeurIPS 2018)
            </a>
            </li>
            <li>
            <a href="https://ml4health.github.io/2018/">
                Machine Learning for Health (ML4H @ NeurIPS 2018)
            </a>
            </li>
        </ul>
        <p> Please consider submitting a short paper!
        </p>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Aug 2018] I'll present a tutorial -- 
        <a href="mlhc2018_tutorial.html">
            "Machine Learning for Clinicians: Advances for Multi-Modal Health Data"
        </a>
        -- <a href="https://www.mlforhc.org"> at MLHC 2018</a>.
        </h4>
        <p>
            Goal: make healthcare professionals aware of the latest tools from ML and help them be research effective collaborators.
        <a href="mlhc2018_tutorial.html">
                Please visit the 
                Tutorial Website 
            </a>
            (with outline, slides, and full bibliography).
        </p>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Aug 2018] I have joined the faculty at Tufts' Computer Science Department!
        </h4>
        <p>
            I'm actively looking for students (ugrad and Ph.D.) for various research projects. Please contact me if interested.
        </p>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Apr 2018] <a href="{static}/images/SoCalNLPBestPaperCertificate.jpg">Best Paper Award</a> at <a href="https://socalnlp.github.io/symp18/index.html">SoCalNLP 2018</a>
        </h4>
        <p>
            Our winning <a href="{static}/papers/HughesHopeWeinerEtAl_SoCalNLP_2018.pdf">2-page short paper</a> was a compact summary of our AISTATS 2018 paper: <a href="{static}/papers/HughesEtAl_AISTATS_2018.pdf">Semi-Supervised Prediction-Constrained Topic Models</a>.
            Thanks to co-author Gabe for presenting the work, to the SoCal NLP organizers for hosting, and to Amazon for sponsoring the award.
        </p>
    </li>
    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Jan 2018] Paper accepted to AISTATS 2018.
        </h4>
        <p>
            Our paper -- <a href="{static}/papers/HughesEtAl_AISTATS_2018.pdf">Semi-Supervised Prediction-Constrained Topic Models</a> -- describes a new framework for training topic models and other latent variable models to improve <i>supervised</i> predictions while still providing good generative models with interpretable topics. The new approach fixes core issues with past methods like sLDA, and shines especially in semi-supervised tasks, when only a small fraction of training examples are labeled.
        </p>
    </li>
    <li class="list-group-item">
    <h4 class="list-group-item-heading">
    [Dec 2017] Presenting at NIPS 2017 Workshops
    </h4>
    <p class="list-group-item-text">
        &#8226;
        <a href="/papers/HughesEtAl_NIPSML4H_2017.pdf">
            Poster: Prediction-constrained Topic Models for Antidepressant Recommendation
        </a>
        at
        <a href="https://ml4health.github.io/2017/">
            ML for Health Workshop (NIPS ML4H 2017)
        </a>
    </p>
    <p class="list-group-item-text">
        &#8226;
        <a href="https://arxiv.org/pdf/1711.06178.pdf">
            Poster and Talk (by Mike Wu): Optimizing deep models with tree-regularization
        </a>
        at
        <a href="https://sites.google.com/view/timl-nips2017/schedule?authuser=0">
            Transparent and Interpretable ML workshop (NIPS TIML 2017)
        </a>
        (will also appear in AAAI '18)
    </p>
    </li>

    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Nov 2017] Paper accepted to AAAI 2018.
        </h4>
        <p class="list-group-item-text">
            <a href="https://arxiv.org/pdf/1711.06178.pdf">
            Beyond Sparsity: Tree Regularization of Deep Models for Interpretability
            [PDF]
            </a>
        </p> 
        <p>
            Our paper describes a new regularization method to <emph>optimize</emph> recurrent neural networks to have more interpretable decision boundaries (closer to the decision trees that clinicians like).
        </p>
    </li>


    <li class="list-group-item">
    <h4 class="list-group-item-heading">
    [Nov 2017] Invited talk at <a href="https://www.ll.mit.edu">MIT Lincoln Laboratory</a>
    </h4>
    <p class="list-group-item-text">
        "Optimizing Machine Learning Models for Clinical Interpretability"
    </p>
    <p class="list-group-item-text">
        Slides:
        <a href="https://www.dropbox.com/s/4aj9j1c2yw3kybj/20171114_LincolnLab.pdf?dl=0">
         [slides.pdf, 5 MB]
        </a>
    </p>
    </li>

    <li class="list-group-item">
    <h4 class="list-group-item-heading">
    [Sep 2017] Organizing 
    <a href="https://ml4health.github.io/2017/">
        Machine Learning for Health (ML4H) workshop at NIPS 2017
    </a>
    </h4>
    <p>Please <a href="https://ml4health.github.io/2017/pages/call-for-papers.html#submission_instructions">submit some awesome papers!</a></p>
    </li>

    <li class="list-group-item">
    <h4 class="list-group-item-heading">
    [Mar 2017] Presented paper on ICU intervention prediction at 
        <a href="https://www.amia.org/jointsummits2017/papers/">
            AMIA CRI '17
        </a>
    </h4>
    <p class="list-group-item-text">
        Nominated for Clinical Informatics Research Award (1 of 7 nominees)
    </p>
    <p class="list-group-item-text">
        <a href="/papers/GhassemiWuHughesEtAl_AMIACRI2017.pdf">
        paper [PDF] 
        </a>
        &#8226;
        <a href="/talks/20170328_AMIACRI2017.pdf">
         slides [PDF]
        </a>
    </p>
    </li>


    <li class="list-group-item">
    <h4 class="list-group-item-heading">
    [Feb 2017] Invited talk on BNPy at Boston Bayesians meetup
    </h4>
    <p class="list-group-item-text">
        <a href="https://www.meetup.com/Boston-Bayesians/events/237060774/">
        Event website and talk abstract
        </a>
    </p>
    <p class="list-group-item-text">
        Slides from my talk:
        <a href="https://www.dropbox.com/s/rpdyra2pznfr98i/20170207_BNPyTalk_BostonBayesians.pptx?dl=0">
         [slides.pptx, 73 MB]</a>
        <a href="https://www.dropbox.com/s/agf93kdfbbnthn5/20170207_BNPyTalk_BostonBayesians_Small.pdf?dl=0">
         [slides.pdf, 23 MB]</a>
    </p>
    </li>


    <li class="list-group-item">
    <h4 class="list-group-item-heading">
    [Dec 2016] BNPy software tutorial at NIPS 2016 workshop
    </h4>
    <p class="list-group-item-text">
        Slides from my talk:
        <a href="https://www.dropbox.com/s/oalse0q7q0c7fmt/20161207_bnpytalk.pptx?dl=0">
         [slides.pptx]</a>
        <a href="https://www.dropbox.com/s/2c0c7rtp5uxk0hj/20161207_bnpytalk.pdf?dl=0">
         [slides.pdf]</a>
    </p>
    <p class="list-group-item-text">
        New: <a href="https://bnpy.readthedocs.io/en/latest/index.html">
        BNPy project website </a>
        with example gallery
    </p>
    </li>

    <li class="list-group-item">
    <h4 class="list-group-item-heading">
    [Dec 2016] Posters at NIPS 2016 Workshops
    </h4>
    <p class="list-group-item-text">
        <a href="/papers/HughesElibolMcCoyPerlisDoshi_MLHCWorkshopAtNIPS2016.pdf">
        Fast per-document inference for supervised topic models</a>
        at
        <a href="http://www.nipsml4hc.ws/home">
            ML for Health workshop.
        </a>
    </p>
    <p class="list-group-item-text">
        <a href="/papers/JiHughesSudderth_PracticalBNPWorkshop_2016.pdf">
        HDP models for natural images</a>
        at
        <a href="https://sites.google.com/site/nipsbnp2016/">
            Practical BNP workshop.
        </a>
    </p>
    </li>

    <li class="list-group-item">
    <h4 class="list-group-item-heading">
    [Sep 2016] Organizing Workshop at NIPS '16: Practical Bayesian Nonparametrics
    </h4>
    <p class="list-group-item-text" style="overflow-wrap: break-word; word-wrap: break-word; word-break: break-all;">
        Please consider submitting to our workshop: 
    <a href="https://sites.google.com/site/nipsbnp2016/">https://sites.google.com/site/nipsbnp2016/</a> 
    </p>
    </li>

  <li class="list-group-item">
    <h4 class="list-group-item-heading">
    [Aug 2016] Started post-doc at Harvard
    </h4>
    <p class="list-group-item-text">
        You can now find me at my new office in Maxwell-Dworkin (MD 209).
    </p>
    </li>

    <li class="list-group-item">
    <h4 class="list-group-item-heading">
    [May 2016] Successful Ph.D. defense!
    </h4>
    <p class="list-group-item-text">
        Many thanks to family and friends who supported me along the way.
    </p>
    </li>


    <li class="list-group-item">
    <h4 class="list-group-item-heading">
    [Jan 2016] Invited talks on my thesis.
    </h4>
    <p class="list-group-item-text">
    I visited several research groups at Northeastern, U. Washington, and MIT to
    discuss results from my thesis work trying to make 
    effective variational inference for clustering that scales to millions of examples.
    <a href="https://dl.dropboxusercontent.com/u/568924/InvitedTalk_ScalableInferenceThatAdaptsClusters_v20160123.pdf">
    [slides PDF] </a>
    <a href="https://dl.dropboxusercontent.com/u/568924/InvitedTalk_ScalableInferenceThatAdaptsClusters_v20160123.pptx">
    [slides PPTX] </a>
    </p>
    </li>

    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Dec 2015] Invited talk at NIPS 2015 workshop.
        </h4>
        <p class="list-group-item-text">
            I gave an invited talk at the <a href="https://sites.google.com/site/nipsbnp2015">
            Bayesian Nonparametrics: The Next Generation workshop </a>
            about my thesis work building 
            effective variational inference for models based 
            on the Dirichlet process and its hierarchical variants.
          <a href="https://dl.dropboxusercontent.com/u/568924/NIPSBNP2015_v1210.pdf"> [slides PDF] </a>
    </p>
    </li>


    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [Sept 2015] Paper accepted at NIPS 2015.
        </h4>
        <p class="list-group-item-text">
            <a href="/papers/HughesStephensonSudderth_NIPS_2015.pdf">
            Our paper [PDF] 
            </a>
            describes a new algorithm for Bayesian nonparametric hidden Markov models that can handle hundreds of sequences and add or remove hidden states during a single training run.
        </p>
    </li>

    <li class="list-group-item">
        <h4 class="list-group-item-heading">
        [May 2015] Paper accepted at AISTATS 2015.
        </h4>
        <p class="list-group-item-text">
            <a href="/papers/HughesKimSudderth_AISTATS_2015.pdf">
            Our paper [PDF] 
            </a>
            describes a new algorithm for topic models
            that can effectively remove redundant or junk topics during a single training run.
        </p>
    </li>

    
</ul>
